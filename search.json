[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "AI総合演習",
    "section": "",
    "text": "ようこそ\nこの資料は徳島大学 教養教育院・教養科目群・自然と技術の「AI総合演習」（INTT1520JLAS01）についての補助教材です。講義で扱った内容について、Quartoによるブック形式で提供しています。内容は、講義名のとおり、AI（人工知能）に含まれる機械学習、深層学習について、Pythonプログラミングによる演習形式で行います。\n講義の計画は以下の通りです。2023年5月12日現在、前期の講義が進行中であり、内容は順次追加されていきます。\nこのページの元となるファイルはGitHubリポジトリでも公開しています。そこでは講義中に投影したスライド資料（一部、公開のために調整したものもあり）も含まれます。内容の誤りや誤字脱字、不明点や改善のためのコメント等はGitHub issuesあるいはpull requestを通して行うことが可能です。資料の品質向上のために協力いただけますと幸いです。"
  },
  {
    "objectID": "index.html#ライセンス",
    "href": "index.html#ライセンス",
    "title": "AI総合演習",
    "section": "ライセンス",
    "text": "ライセンス\n資料のうち、プログラム部分以外（文章や画像）はクリエイティブ・コモンズ 表示 - 非営利 - 改変禁止 4.0 国際 (CC BY-NC-ND 4.0)、プログラム部分はMITライセンスに従い、利用できます。"
  },
  {
    "objectID": "week01/guidance.html#参考資料url",
    "href": "week01/guidance.html#参考資料url",
    "title": "ガイダンス",
    "section": "参考資料・URL",
    "text": "参考資料・URL\n\n(小林一郎 2008)\n(谷口忠大 2020)\n(赤穂昭太郎 ほか 2023)\n(岡野原大輔 2022b)\n(岡野原大輔 2022a)\n(岡谷貴之 2022)\n(AI白書編集委員会 2022)\n\n\n\n\n\nAI白書編集委員会. 2022. AI白書2022. KADOKAWA.\n\n\n小林一郎. 2008. 人工知能の基礎. Computer science library ; 13. サイエンス社. http://id.ndl.go.jp/bib/000009788211.\n\n\n岡谷貴之. 2022. 深層学習 = Deep Learning. 改訂第2版 版. 機械学習プロフェッショナルシリーズ. 講談社. http://id.ndl.go.jp/bib/031901202.\n\n\n岡野原大輔. 2022a. ディープラーニングを支える技術. Tech×Books plus 2. 技術評論社. http://id.ndl.go.jp/bib/032086743.\n\n\n———. 2022b. ディープラーニングを支える技術 : 「正解」を導くメカニズム〈技術基礎〉. Tech×Books plus. 技術評論社. http://id.ndl.go.jp/bib/031881422.\n\n\n谷口忠大. 2020. イラストで学ぶ人工知能概論 = An Illustrated Guide to Artificial Intelligence. 改訂第2版 版. 講談社. http://id.ndl.go.jp/bib/030810109.\n\n\n赤穂昭太郎, 今泉允聡, 内田誠一, 清智也, 高野渉, 辻真吾, 原尚幸, ほか. 2023. 応用基礎としてのデータサイエンス : AI×データ活用の実践. 編集者： 北川源四郎 と 竹村彰通. データサイエンス入門シリーズ. 講談社. http://id.ndl.go.jp/bib/032637501."
  },
  {
    "objectID": "week02/index.html#この章の参考資料url",
    "href": "week02/index.html#この章の参考資料url",
    "title": "プログラミング入門",
    "section": "この章の参考資料・URL",
    "text": "この章の参考資料・URL\n\n(池内孝啓 と 片柳薫子 2020)\n(有賀友紀 と 大橋俊介 2021)\n(Grus と 菊池彰 2020)\n(Sweigart と 相川愛三 2023)\n(八谷大岳 2020)\nhttps://docs.python.org/3/\nhttps://www.python.jp/train/index.html\n\n\n\n\n\nGrus, Joel, と 菊池彰. 2020. ゼロからはじめるデータサイエンス : Pythonで学ぶ基本と実践. 翻訳者： 菊池彰. 第2版 版. オライリー・ジャパン. http://id.ndl.go.jp/bib/030372878.\n\n\nSweigart, Al, と 相川愛三. 2023. 退屈なことはPythonにやらせよう : ノンプログラマーにもできる自動化処理プログラミング. 翻訳者： 相川愛三. 第2版 版. オライリー・ジャパン.\n\n\n八谷大岳. 2020. ゼロからつくるPython機械学習プログラミング入門 = Introduction to Machine Learning from Scratch with Python. 機械学習スタートアップシリーズ. 講談社. http://id.ndl.go.jp/bib/030584765.\n\n\n有賀友紀, と 大橋俊介. 2021. RとPythonで学ぶ実践的データサイエンス&機械学習. 増補改訂版. 技術評論社. http://id.ndl.go.jp/bib/031401828.\n\n\n池内孝啓, と 片柳薫子. 2020. PythonユーザのためのJupyter〈実践〉入門. 改訂版. 技術評論社. http://id.ndl.go.jp/bib/030570561."
  },
  {
    "objectID": "week02/0201_pandas.html",
    "href": "week02/0201_pandas.html",
    "title": "1  pandas基礎",
    "section": "",
    "text": "pandasは、Pythonでさまざまなデータ分析を効率的に行うことができるライブラリです。ここではpandasの基本的な使い方を学びます。\nまずはpandasをインポートします。もしpandasがインストールされていない場合、pip install pandasでインストールしてください。\n\n# pandasの読み込み ... pdとして参照できるようにします\nimport pandas as pd\n\n\n# seies\nsr = pd.Series([1, 2, 3, 4, 5])\nsr\n\n0    1\n1    2\n2    3\n3    4\n4    5\ndtype: int64\n\n\n\nimport numpy as np\n\ndata = np.array(\n    [\n        [63.5, 100, 64, 110, 85],\n        [6, 3.5, 5.4, 6.5, 60],\n        [\"レッサーパンダ\", \"ホオジロカンムリヅル\", \"コツメカワウソ\", \"カナダガン\", \"チンパンジー\"],\n    ]\n).T\n\n\n# data frame (df)\ndf = pd.DataFrame(data, columns=[\"body_length_cm\", \"weight_kg\", \"name\"])\n\ndf\n\n\n\n\n\n\n\n\nbody_length_cm\nweight_kg\nname\n\n\n\n\n0\n63.5\n6\nレッサーパンダ\n\n\n1\n100\n3.5\nホオジロカンムリヅル\n\n\n2\n64\n5.4\nコツメカワウソ\n\n\n3\n110\n6.5\nカナダガン\n\n\n4\n85\n60\nチンパンジー"
  },
  {
    "objectID": "week02/0202_matplotlib.html",
    "href": "week02/0202_matplotlib.html",
    "title": "2  データの可視化",
    "section": "",
    "text": "# 利用するライブラリを読み込む\n# as で別名をつけることができる（長いライブラリ名の省略）\nimport japanize_matplotlib  # matplotlibの日本語化\nimport matplotlib.pyplot as plt  # データ可視化\nimport numpy as np  # 数値計算用\nimport pandas as pd  # 表形式データの操作\nimport polars as pl  # pandas と同じく表形式データの操作\n\nデータフレームの操作にはpolarsとpandasの2つのライブラリを使用すると便利です。\n\n# データ（csvファイル）の読み込み\n# ファイルがある場所（パス）を指定する\n# ウェブ上のデータを読み込む場合はURLを指定する\ndf = pl.read_csv(\n    \"https://raw.githubusercontent.com/uribo/cue2022aw_r104/main/data-raw/shikoku_kome_sisyutu2019to2021/20221121T014749Z-f75ff/shikoku_kome_sisyutu2019to2021.csv\"\n)\n\n\n# 読み込んだデータの確認\n# shape: データの行数と列数を確認する\ndf.shape\n\n(864, 6)\n\n\n\n# 型の確認\ndf.dtypes\n\n[Int64, Utf8, Int64, Utf8, Utf8, Int64]\n\n\n\n2.0.1 データの可視化\nコードセルでdfと入力して実行すると、データフレームの中身が表示されます。 一方、行数の多いデータを出力すると画面が埋まってしまうので、一部だけを確認したいこともあります。 その場合、headやtailを使います。これにより、データフレームの先頭行や末尾行を表示することができます。括弧内の値は表示する行数です。\n\n# 先頭3行を表示する\ndf.head(3)\n\n\nshape: (3, 6)\n\n\n\nym\n品目分類\n市区町村コード\n市\n項目\nvalue\n\n\ni64\nstr\ni64\nstr\nstr\ni64\n\n\n\n\n201901\n\"アイスクリーム・シャーベット…\n36201\n\"徳島市\"\n\"支出金額_複数単位\"\n367\n\n\n201901\n\"アイスクリーム・シャーベット…\n36201\n\"徳島市\"\n\"購入頻度_100世帯当たり\"\n123\n\n\n201901\n\"殺虫・防虫剤\"\n36201\n\"徳島市\"\n\"支出金額_複数単位\"\n7\n\n\n\n\n\n\n\n# 末尾2行を表示する\ndf.tail(2)\n\n\nshape: (2, 6)\n\n\n\nym\n品目分類\n市区町村コード\n市\n項目\nvalue\n\n\ni64\nstr\ni64\nstr\nstr\ni64\n\n\n\n\n202112\n\"米\"\n39201\n\"高知市\"\n\"支出金額_複数単位\"\n1557\n\n\n202112\n\"米\"\n39201\n\"高知市\"\n\"購入頻度_100世帯当たり\"\n73\n\n\n\n\n\n\n続いて、簡単なグラフを作成してみましょう。matplotlibにはPythonでグラフを作成する際に便利な関数をまとめたpyplotというモジュールがあります。pyplotをpltという名前でインポートしておきます。\n\n# import matplotlib.pyplot as plt # 最初のコードセルで実行済み\n\npltには、plotやscatterなどの関数があります。plotは折れ線グラフを、scatterは散布図を作成します。今回は棒グラフを作成したいのでbarが対応します。\nこれらの関数の引数には、グラフに描画するx軸の値とy軸の値（変数）を指定します。\nmatplotlibがサポートするグラフの種類や詳しい関数の利用方法は公式ドキュメントを参照してください。\n\n# 棒グラフを作成\n# x軸には品目分類、y軸にはvalueを指定する\nplt.bar(df[\"品目分類\"], df[\"value\"])\n# plt.show() # グラフを表示する\n\n&lt;BarContainer object of 864 artists&gt;\n\n\n\n\n\n別のグラフを作成してみましょう。\npolarsライブラリのデータ操作関数を使い、一部のデータを抽出してグラフを作成してみます。\n\ndf2 = df.filter((pl.col(\"項目\") == \"支出金額_複数単位\") & (pl.col(\"市区町村コード\") == 36201))\ndf2 = df2.select(\"ym\", \"品目分類\", \"value\")\ndf2.head(4)\n\n\nshape: (4, 3)\n\n\n\nym\n品目分類\nvalue\n\n\ni64\nstr\ni64\n\n\n\n\n201901\n\"アイスクリーム・シャーベット…\n367\n\n\n201901\n\"殺虫・防虫剤\"\n7\n\n\n201901\n\"米\"\n1138\n\n\n201902\n\"アイスクリーム・シャーベット…\n244\n\n\n\n\n\n\n上記のコードは以下のコードの実行結果と同じです。 polarsでは、.を使って処理内容をつなげて記述することができます。こうすることで変数への代入の手間がなくなるとともにコードを簡潔に記述できる利点があります。\n\ndf2 = df.filter((df[\"項目\"] == \"支出金額_複数単位\") & (df[\"市区町村コード\"] == 36201)).select(\n    \"ym\", \"品目分類\", \"value\"\n)\ndf2.head(4)\n\n\nshape: (4, 3)\n\n\n\nym\n品目分類\nvalue\n\n\ni64\nstr\ni64\n\n\n\n\n201901\n\"アイスクリーム・シャーベット…\n367\n\n\n201901\n\"殺虫・防虫剤\"\n7\n\n\n201901\n\"米\"\n1138\n\n\n201902\n\"アイスクリーム・シャーベット…\n244\n\n\n\n\n\n\nデータの加工が済んだのでグラフを作成します。品目分類別に折れ線グラフを作成したいので、groupby関数を使います。groupby関数は、指定した列の値ごとにデータをグループ化します。今回はitem列の値ごとにグループ化します。\n\n# pandasデータフレームに変換\ndf_pnd = df2.to_pandas()\n# 年月の表現を変換 (i64クラスの年月をdatetime形式に変換)\ndf_pnd[\"ym\"] = pd.to_datetime(df_pnd[\"ym\"], format=\"%Y%m\")\n\n# 品目ごとにデータフレームをグループ化\ngrouped = df_pnd.groupby(\"品目分類\")\n\n# グループごとにプロット\nfor item, group in grouped:\n    plt.plot(group[\"ym\"], group[\"value\"], label=item)\n\nplt.xlabel(\"年月\")\nplt.ylabel(\"金額\")\nplt.title(\"徳島市における品目分類別の支出金額の推移\")\nplt.legend()\nplt.grid(True)\nplt.show()\n\n\n\n\n\n2.0.1.1 棒グラフの塗り分け\n\n# グループごとに値を集計\ngrouped_df = df2.groupby(\"品目分類\").agg(total_value=pl.col(\"value\").sum())\n# グループ名と集計された値を取得\ngroups, aggregated_values = grouped_df.get_columns()\n\n# カラーマップを作成\ncolors = plt.cm.viridis(np.linspace(0, 1, len(groups)))\n\n# 棒グラフを描画し、グループごとに塗り分け\nplt.bar(groups, aggregated_values, color=colors)\n\nplt.xlabel(\"品目\")\nplt.ylabel(\"総支出金額\")\nplt.title(\"徳島市における品目別支出金額総計\")\nplt.show()\n\n\n\n\n\n\n\n2.0.2 インタラクティブに操作可能な図の作成\nplotlyライブラリを使うとインタラクティブに操作できるグラフを作成できます。\n\nimport plotly.graph_objects as go\n\n\n# 棒グラフを作成\nfig = go.Figure(data=[go.Bar(x=groups, y=aggregated_values)])\n\n\n# グラフのタイトルと軸ラベルを設定\nfig.update_layout(\n    title=\"徳島市における品目別支出金額総計\",\n    xaxis_title=\"品目\",\n    yaxis_title=\"総支出金額\",\n)\n\n# グラフを表示\nfig.show()"
  },
  {
    "objectID": "week03/index.html#この章の参考資料url",
    "href": "week03/index.html#この章の参考資料url",
    "title": "機械学習の背景・数理",
    "section": "この章の参考資料・URL",
    "text": "この章の参考資料・URL\n\n(石川聡彦 2018)\n(椎名洋 ほか 2019)\n(八谷大岳 2020)\n(吉田拓真 と 尾原颯 2018)\n\n\n\n\n\n八谷大岳. 2020. ゼロからつくるPython機械学習プログラミング入門 = Introduction to Machine Learning from Scratch with Python. 機械学習スタートアップシリーズ. 講談社. http://id.ndl.go.jp/bib/030584765.\n\n\n吉田拓真, と 尾原颯. 2018. 現場で使える!NumPyデータ処理入門 : 機械学習・データサイエンスで役立つ高速処理手法. 翔泳社. http://id.ndl.go.jp/bib/029316312.\n\n\n椎名洋, 姫野哲人, 保科架風, と 清水昌平. 2019. データサイエンスのための数学 = Mathematics for Data Science. 編集者： 清水昌平. データサイエンス入門シリーズ. 講談社. http://id.ndl.go.jp/bib/029903862.\n\n\n石川聡彦. 2018. 人工知能プログラミングのための数学がわかる本 = MATHEMATICS FOR AI PROGRAMMING. KADOKAWA. http://id.ndl.go.jp/bib/028819866."
  },
  {
    "objectID": "week03/03_mathematics.html#利用するライブラリの読み込み",
    "href": "week03/03_mathematics.html#利用するライブラリの読み込み",
    "title": "3  機械学習で用いる数学の基礎",
    "section": "3.1 利用するライブラリの読み込み",
    "text": "3.1 利用するライブラリの読み込み\nPython標準ライブラリおよびJupyterHub環境（hub-scipy-notebookを想定）で導入済みのライブラリを使用します。ここで扱う数学的な処理は標準ライブラリのmathと数値計算、多次元配列を扱うライブラリであるNumPyです。どちらも同様の機能を提供します。\n\n# 利用するライブラリを読み込む\n# as で別名をつけることができる（長いライブラリ名を省略）\nimport math # 数学演算のための標準ライブラリ\nimport matplotlib.pyplot as plt # グラフ作成用\nimport japanize_matplotlib # matplotlibの日本語化\nimport numpy as np # 数値計算用"
  },
  {
    "objectID": "week03/03_mathematics.html#変数定数関数",
    "href": "week03/03_mathematics.html#変数定数関数",
    "title": "3  機械学習で用いる数学の基礎",
    "section": "3.2 変数・定数・関数",
    "text": "3.2 変数・定数・関数\n\n\n\n変数・定数・関数の関係\n\n\n\n変数: さまざまな値を取り得る値\n定数: 決められた値\n関数: 入力と出力の関係性を表す数式。入力\\(x\\)が決まると出力\\(y\\)の値も決まる、一対一の関係。\n\n消費税率10%の店で100円のトマトを3個買うとき…\n\nTOMATO_PRICE = 100\nTAX = 10\nn = 3\n\nprint(\"金額: \", (TOMATO_PRICE + (TOMATO_PRICE/TAX)) * n, \"円\")\n\n金額:  330.0 円\n\n\n同じ店で同じトマトを5個買うとき…\n\nn = 5\n\nprint(\"金額: \", (TOMATO_PRICE + (TOMATO_PRICE/TAX)) * n, \"円\")\n\n金額:  550.0 円\n\n\n変わらないのはトマトの価格と消費税率（TOMATO_PRICEとTAX）… 定数1\n変わったのはトマトの個数 … 変数\nこれらの定数と変数の関係を関数にまとめてみましょう。 Pythonでは関数の定義をdef文を使って行います。\n\n# 1個100円で消費税率10%の商品に対して、\n# 個数に応じていくらになるかを求める関数\ndef fn_tomato(n = 1):\n  PRICE = 100\n  TAX = 0.1\n  price_in_tax = PRICE + PRICE * TAX\n  # returnで関数の戻り値を指定\n  # return 文を省略すると関数は None を返す\n  return price_in_tax * n\n\n\nprint(\"金額: \", fn_tomato(3), \"円\") # 3個\nprint(\"金額: \", fn_tomato(5), \"円\") # 5個\n\n金額:  330.0 円\n金額:  550.0 円\n\n\n関数を用いることで、定数の記述を省略し、変数だけを変更した計算が容易に行えるようになりました。このように関数では、関連のある一連の処理をまとめて再利用することができて便利です。また、コードに問題が生じたときも関数の部分に注目して修正を行える利点があります。"
  },
  {
    "objectID": "week03/03_mathematics.html#一次関数",
    "href": "week03/03_mathematics.html#一次関数",
    "title": "3  機械学習で用いる数学の基礎",
    "section": "3.3 一次関数",
    "text": "3.3 一次関数\n一次関数\\(y=ax+b\\)について考えます。この一次関数では2つの定数\\(a\\)と\\(b\\)が存在し、それぞれ傾きと切片として機能します。\nここで、定数が異なる一次関数がどのようにグラフ上で変化するか確認しましょう。変数である\\(x\\)にはNumPyのlinspace()関数により生成した隣接する項との差が一定の等差数列を与えます。\n\n# 2つの一次関数によるグラフを作成する\nx = np.linspace(0, 10, 5) # 0から10までの公差が2.5の等差数列を生成\n\n# 定数が異なる一次関数に変数を当てはめてyの値を得る\ny1 = 3 * x + 5\ny2 = 2.4 * x + 2\n\n# xとyの関係をグラフに描画\nplt.grid(True)\nplt.plot(x, y1, label=\"式 y = 3x + 5\", color=\"#5097F8\")\nplt.plot(x, y2, label=\"式 y = 2.4x + 2\", color=\"#fc5998\")\nplt.legend(loc=\"upper left\")\nplt.show()\n\n\n\n\n一次関数のグラフは直線を描きます。異なる定数からなる一次関数のグラフは、異なる直線になっていることがわかります。\n機械学習・深層学習では、このような関数の出力に影響を及ぼす「重み」を変数として学習し、未知のデータに対しては定数として「重み」を利用します。特に深層学習では複数の中間層が「重み」をもつことになり、より柔軟な表現力を得ることがモデルの性能向上に貢献しています。"
  },
  {
    "objectID": "week03/03_mathematics.html#平方根",
    "href": "week03/03_mathematics.html#平方根",
    "title": "3  機械学習で用いる数学の基礎",
    "section": "3.4 平方根",
    "text": "3.4 平方根\n平方根はmath、NumPyで利用方法が異なります。 それぞれのライブラリでの平方根の使い方をみましょう。\n\\(\\sqrt{2}\\)\n\nmath.sqrt(2)\n\nnp.sqrt(2)\n\n1.4142135623730951\n\n\n\\(\\sqrt{3}\\)\n\nmath.sqrt(3)\n\nnp.sqrt(3)\n\n1.7320508075688772\n\n\n\n# 問題: 「富士山麓オウム鳴く」となる整数は？\nx = x\nnp.sqrt(x)"
  },
  {
    "objectID": "week03/03_mathematics.html#累乗",
    "href": "week03/03_mathematics.html#累乗",
    "title": "3  機械学習で用いる数学の基礎",
    "section": "3.5 累乗",
    "text": "3.5 累乗\n\n**演算子\nmathライブラリのpow()関数\nnumpyライブラリのpower()関数\n\n\nbase = 3 # 底\nexponent = 2 # 指数\n\n\nbase**exponent\n\n9\n\n\n\nmath.pow(base, exponent)\n\n9.0\n\n\n\nnp.power(base, exponent)\n\n9"
  },
  {
    "objectID": "week03/03_mathematics.html#指数関数と対数関数",
    "href": "week03/03_mathematics.html#指数関数と対数関数",
    "title": "3  機械学習で用いる数学の基礎",
    "section": "3.6 指数関数と対数関数",
    "text": "3.6 指数関数と対数関数\n\n3.6.1 指数関数\n指数関数… 指数を変数とした関数\n\n# 引数として与えられた数値の指数関数の値を返す\n# e^2\n# eは自然対数の底。およそ2.71828\nnp.exp(2)\n\n# np.power()で同じ値が得られることを確認\n# np.power(2.71828, 2)\n\n7.38905609893065\n\n\n\n# 0から10まで0.1刻みの配列を生成\nx = np.arange(0, 10, 0.1)\n\ny = np.exp(x)\n\nplt.suptitle(\"指数関数のグラフ\")\nplt.plot(x, y, color = \"#5097F8\")\nplt.grid(True)\n\nplt.show()\n\n\n\n\n\n\n3.6.2 対数関数\n\nx = np.exp(2)\nnp.log(x)\n\n2.0\n\n\n\n# 0.1から10まで0.1刻みの配列を生成\nx = np.arange(0.1, 10, 0.1)\n\ny = np.log(x)\n\nplt.suptitle(\"対数関数のグラフ\")\nplt.plot(x, y, color = \"#5097F8\")\nplt.grid(True)\n\nplt.show()\n\n\n\n\n常用対数\n\nnp.log10(10)\n\n1.0"
  },
  {
    "objectID": "week03/03_mathematics.html#ベクトル",
    "href": "week03/03_mathematics.html#ベクトル",
    "title": "3  機械学習で用いる数学の基礎",
    "section": "3.7 ベクトル",
    "text": "3.7 ベクトル\nリストは行ベクトルとして機能します。ただしベクトル同士の演算を行うことは難しいです。\n\nvector = [1, 2, 3, 4, 5]\nprint(vector)\n\n[1, 2, 3, 4, 5]\n\n\nそのためベクトル演算を実現するにはNumPyのarray()関数を利用する方法が簡単です。なおのarray()関数では厳密に行ベクトルまたは列ベクトルを区別せずに1次元配列を表現するために使用されます。\n\nvector = np.array([1, 2, 3, 4, 5])\n\n\n# ベクトルの和\nvector + vector\n\narray([ 2,  4,  6,  8, 10])\n\n\n\n# ベクトルの差\nvector - np.array([0, 2, 4, 1, 1])\n\narray([ 1,  0, -1,  3,  4])\n\n\n\n# リストによるベクトルでは+演算子を使ったベクトルの和の計算が行えない\n[1, 2, 3, 4, 5]+[1, 2, 3, 4, 5]\n\n[1, 2, 3, 4, 5, 1, 2, 3, 4, 5]\n\n\nベクトルの和は同じ成分の数からなるベクトル同士でないと計算できません。\n\nvector2 = np.array([6, 7])\n\nvector + vector2\n\nValueError: operands could not be broadcast together with shapes (5,) (2,) \n\n\nNumPyでベクトルの要素数を知る方法は、numpy.arrayオブジェクトのsize属性を使用する、len()関数を用いるなどがあります。\n\n# numpy.arrayの要素数を確認\nvector.size\n\nnp.size(vector)\nnp.size(vector2)\n\nlen(vector)\n\n5\n\n\n\n3.7.1 ベクトルの内積: 同一次元のベクトル同士のかけ算\n\n# ベクトル u と v を定義\nu = np.array([1, 2, 3])\nv = np.array([4, 5, 6])\n\n# NumPyのdot関数を使って内積を計算\ninner_product = np.dot(u, v)\n\nprint(\"内積:\", inner_product)\n\n内積: 32\n\n\n\n# 検算\n(1 * 4) + (2 * 5) + (3 * 6)\n\n32\n\n\n内積は次元の等しいベクトル同士でないと求められません。\n\nnp.dot(u, np.array([3, 2]))\n\nValueError: shapes (3,) and (2,) not aligned: 3 (dim 0) != 2 (dim 0)"
  },
  {
    "objectID": "week03/03_mathematics.html#行列",
    "href": "week03/03_mathematics.html#行列",
    "title": "3  機械学習で用いる数学の基礎",
    "section": "3.8 行列",
    "text": "3.8 行列\n行列の表現もNumPyを使うと演算（行列の加算、減算、乗算、転置、逆行列）が簡単に行えるようになります。\n\nmatrix = np.array([\n    [1, 2, 3],\n    [4, 5, 6],\n    [7, 8, 9]\n])\n\nmatrix\n\narray([[1, 2, 3],\n       [4, 5, 6],\n       [7, 8, 9]])\n\n\n\n3.8.1 行列の転置\n\n# 行列の縦と横を入れ替える\nmatrix.T\n\narray([[1, 4, 7],\n       [2, 5, 8],\n       [3, 6, 9]])"
  },
  {
    "objectID": "week03/03_mathematics.html#footnotes",
    "href": "week03/03_mathematics.html#footnotes",
    "title": "3  機械学習で用いる数学の基礎",
    "section": "",
    "text": "Pythonでは変数と定数を明確に区分する仕組みはありません。Pythonコミュニティにおけるコードの記述ルールをまとめたコーディング規約であるPEP 8では定数の名前は大文字で書き、単語をアンダースコアで区切ることが明記されています。↩︎"
  },
  {
    "objectID": "week04/index.html#この章の参考資料url",
    "href": "week04/index.html#この章の参考資料url",
    "title": "機械学習モデルの設計と評価",
    "section": "この章の参考資料・URL",
    "text": "この章の参考資料・URL\n\n(岡野原大輔 2022)\n(門脇大輔 ほか 2019)\n(八谷大岳 2020)\n(Géron, 下田倫大, と 長尾高弘 2020)\n(Alice Zheng と ホクソエム 2019)\n\n\n\n\n\nAlice Zheng, Amanda Casari, と ホクソエム. 2019. 機械学習のための特徴量エンジニアリング : その原理とPythonによる実践. 翻訳者： ホクソエム. オライリー・ジャパン. http://id.ndl.go.jp/bib/029512290.\n\n\nGéron, Aurélien, 下田倫大, と 長尾高弘. 2020. scikit-learn、Keras、TensorFlowによる実践機械学習. 翻訳者： 下田倫大 と 長尾高弘. 第2版 版. オライリー・ジャパン. http://id.ndl.go.jp/bib/030701507.\n\n\n八谷大岳. 2020. ゼロからつくるPython機械学習プログラミング入門 = Introduction to Machine Learning from Scratch with Python. 機械学習スタートアップシリーズ. 講談社. http://id.ndl.go.jp/bib/030584765.\n\n\n岡野原大輔. 2022. ディープラーニングを支える技術 : 「正解」を導くメカニズム〈技術基礎〉. Tech×Books plus. 技術評論社. http://id.ndl.go.jp/bib/031881422.\n\n\n門脇大輔, 阪田隆司, 保坂桂佑, と 平松雄司. 2019. Kaggleで勝つデータ分析の技術. 技術評論社. http://id.ndl.go.jp/bib/029976550."
  },
  {
    "objectID": "week04/0401_penguins.html#ペンギンデータ",
    "href": "week04/0401_penguins.html#ペンギンデータ",
    "title": "4  南極大陸に生育するペンギンの体長データ",
    "section": "4.1 ペンギンデータ",
    "text": "4.1 ペンギンデータ\n機械学習による分類問題の例として、南極大陸に生育するペンギンの体長についての観測データを利用します。このデータを使ってペンギンの種類を分類するモデルを構築します。\n\n4.1.1 データの読み込み\nペンギンデータはseabornライブラリに含まれています。データを利用するにはload_dataset()関数で読み込みます。\n\n# ペンギンデータの読み込み\npenguins = sns.load_dataset(\"penguins\")\n\n# pandasのDataFrameとして格納されている\n# type(penguins)\n\n\n\n4.1.2 データの確認\nペンギンデータの中身を確認します。データについて理解を深めるためのいくつかの処理を行ってみましょう。まずはデータフレームオブジェクトの属性の一つ、shapeを使うと、行数と列数を確認できます。\n\npenguins.shape\n\n# 以下のコードの実行はエラーとなる\n# 理由はshapeがデータフレームの属性であるのに対して、\n# shape()はメソッド（関数）であるため\n# penguins.shepe()\n\n(344, 7)\n\n\n以下の例では、いくつかのpandasのデータフレーム関数を使って、データの概要を確認しています。これらは関数として実行するため、末尾に括弧を付けています。\n\n# データフレームの概要\n# 各列（変数）の名前（Column）、欠損値の件数（Non-Null Count）、データ型(Dtype)を表示\npenguins.info()\n\n&lt;class 'pandas.core.frame.DataFrame'&gt;\nRangeIndex: 344 entries, 0 to 343\nData columns (total 7 columns):\n #   Column             Non-Null Count  Dtype  \n---  ------             --------------  -----  \n 0   species            344 non-null    object \n 1   island             344 non-null    object \n 2   bill_length_mm     342 non-null    float64\n 3   bill_depth_mm      342 non-null    float64\n 4   flipper_length_mm  342 non-null    float64\n 5   body_mass_g        342 non-null    float64\n 6   sex                333 non-null    object \ndtypes: float64(4), object(3)\nmemory usage: 18.9+ KB\n\n\nいくつの変数に欠損値があるようです。欠損値の有無は機械学習モデルを実行する際に影響を及ぼす可能性があります。ここでは欠損値への処理を行いませんが、ペンギンデータに欠損値が含まれるということを覚えておきましょう。\nつづいて具体的なデータの中身を確認します。head()関数を使うと、データの先頭から引数で指定した行数を表示できます。tail()関数はデータの末尾から指定した行数を表示するのに利用します。\n\n# 先頭5行の表示\npenguins.head(5)\n\n# 末尾3行の表示\n# penguins.tail(3)\n\n\n\n\n\n\n\n\nspecies\nisland\nbill_length_mm\nbill_depth_mm\nflipper_length_mm\nbody_mass_g\nsex\n\n\n\n\n0\nAdelie\nTorgersen\n39.1\n18.7\n181.0\n3750.0\nMale\n\n\n1\nAdelie\nTorgersen\n39.5\n17.4\n186.0\n3800.0\nFemale\n\n\n2\nAdelie\nTorgersen\n40.3\n18.0\n195.0\n3250.0\nFemale\n\n\n3\nAdelie\nTorgersen\nNaN\nNaN\nNaN\nNaN\nNaN\n\n\n4\nAdelie\nTorgersen\n36.7\n19.3\n193.0\n3450.0\nFemale\n\n\n\n\n\n\n\nここでペンギンデータの変数をまとめておきましょう。このデータには次の変数が含まれます。\n\nspecies: ペンギンの種名。次の3種が含まれます。Adelie（アデリーペンギン）、Chinstrap（ヒゲペンギン）、Gentoo（ジェンツーペンギン）。\nisland: ペンギンが生息する島の名前。次の3つの島が含まれます。Biscoe、Dream、Torgersen。\nbill_length_mm: くちばしの長さ（単位: mm）。\nbill_depth_mm: くちばしの深さ（単位: mm）。くちばしの高さとも言えます。\nflipper_length_mm: 翼の長さ（単位: mm）。ペンギンの場合はひれの長さとも言えます。\nbody_mass_g: 体重（単位: g）。\nsex: 性別。Male（オス）、Female（メス）の2種類。\n\n分類対象として扱うペンギンの種名について、詳しく調べます。次のコードでそれぞれの種名のデータが何件含まれるかを確認します。\n\nprint(\"ペンギンの種類: \", penguins[\"species\"].unique())\n\npenguins.groupby(\"species\").size().reset_index(name=\"count\")\n\nペンギンの種類:  ['Adelie' 'Chinstrap' 'Gentoo']\n\n\n\n\n\n\n\n\n\nspecies\ncount\n\n\n\n\n0\nAdelie\n152\n\n\n1\nChinstrap\n68\n\n\n2\nGentoo\n124\n\n\n\n\n\n\n\n\n\n\n\n\n\nアデリーペンギン\n\n\n\n\n\n\n\nヒゲペンギン\n\n\n\n\n\n\n\nジェンツーペンギン\n\n\n\n\n\n\n\n4.1.3 統計量\npandasのdescribe()関数を使うと、平均値や標準偏差、最小値・最大値といった複数の統計量を一度に確認できます。\n\n# ペンギンデータの統計量の表示\npenguins.describe()\n\n\n\n\n\n\n\n\nbill_length_mm\nbill_depth_mm\nflipper_length_mm\nbody_mass_g\n\n\n\n\ncount\n342.000000\n342.000000\n342.000000\n342.000000\n\n\nmean\n43.921930\n17.151170\n200.915205\n4201.754386\n\n\nstd\n5.459584\n1.974793\n14.061714\n801.954536\n\n\nmin\n32.100000\n13.100000\n172.000000\n2700.000000\n\n\n25%\n39.225000\n15.600000\n190.000000\n3550.000000\n\n\n50%\n44.450000\n17.300000\n197.000000\n4050.000000\n\n\n75%\n48.500000\n18.700000\n213.000000\n4750.000000\n\n\nmax\n59.600000\n21.500000\n231.000000\n6300.000000\n\n\n\n\n\n\n\ndescribe()関数が対象とするのはデータフレームの数値データです。speciesやislandのような文字列データは対象となりません。理由は文字列データは平均値（mean）や標準偏差（std）などの統計量に意味がないためです1。しかし最頻値（top）や最頻値の出現回数（freq）は計算できます。describe()関数のデフォルトでは数値データのみが対象となりますが、引数でinclude=\"all\"を指定することで文字列データも対象となります。\n\n# 文字列の変数も含めた統計量の表示\npenguins.describe(include=\"all\")\n\n\n\n\n\n\n\n\nspecies\nisland\nbill_length_mm\nbill_depth_mm\nflipper_length_mm\nbody_mass_g\nsex\n\n\n\n\ncount\n344\n344\n342.000000\n342.000000\n342.000000\n342.000000\n333\n\n\nunique\n3\n3\nNaN\nNaN\nNaN\nNaN\n2\n\n\ntop\nAdelie\nBiscoe\nNaN\nNaN\nNaN\nNaN\nMale\n\n\nfreq\n152\n168\nNaN\nNaN\nNaN\nNaN\n168\n\n\nmean\nNaN\nNaN\n43.921930\n17.151170\n200.915205\n4201.754386\nNaN\n\n\nstd\nNaN\nNaN\n5.459584\n1.974793\n14.061714\n801.954536\nNaN\n\n\nmin\nNaN\nNaN\n32.100000\n13.100000\n172.000000\n2700.000000\nNaN\n\n\n25%\nNaN\nNaN\n39.225000\n15.600000\n190.000000\n3550.000000\nNaN\n\n\n50%\nNaN\nNaN\n44.450000\n17.300000\n197.000000\n4050.000000\nNaN\n\n\n75%\nNaN\nNaN\n48.500000\n18.700000\n213.000000\n4750.000000\nNaN\n\n\nmax\nNaN\nNaN\n59.600000\n21.500000\n231.000000\n6300.000000\nNaN\n\n\n\n\n\n\n\n\n4.1.3.1 相関係数\n次にペンギンデータの変数間の相関関係をcorr()関数で確認します。相関係数は数値データに対してのみ計算されるため、カテゴリ変数であるspeciesやislandは除外しておきます。さらに、相関係数は欠損値がある場合、適切な値を計算できないため、欠損値を含む行を削除しておきます。\n\n# 欠損値を含む行を削除\npenguins_mod = penguins.dropna()\n\n# カテゴリ変数を含まないデータフレームを作成\npenguins_numeric = penguins_mod.drop(columns=[\"species\", \"island\", \"sex\"])\n\n# 相関係数の計算\ncorrelation_matrix = penguins_numeric.corr()\n\n# 相関係数の表示\ncorrelation_matrix\n\n\n\n\n\n\n\n\nbill_length_mm\nbill_depth_mm\nflipper_length_mm\nbody_mass_g\n\n\n\n\nbill_length_mm\n1.000000\n-0.228626\n0.653096\n0.589451\n\n\nbill_depth_mm\n-0.228626\n1.000000\n-0.577792\n-0.472016\n\n\nflipper_length_mm\n0.653096\n-0.577792\n1.000000\n0.872979\n\n\nbody_mass_g\n0.589451\n-0.472016\n0.872979\n1.000000\n\n\n\n\n\n\n\n相関係数は0から1の間の値となり、絶対値が大きいほど強い相関関係があることを示します。そのため自分自身との相関係数は1となります。符号が正のとき、2つの変数は正の相関関係にあります。つまり、片方の変数が増加すると、もう片方の変数も増加する傾向にあることを示します。一方符号が負のとき、2つの変数は負の相関関係にあります。これは片方の変数が増加すると、もう片方の変数は減少する傾向にあることを意味します。\n\n\n\n4.1.4 データの可視化\nさらにデータへの理解を深めるために、グラフ上にペンギンデータを表現してみます。データ可視化によって、細かな傾向や全体的な特徴を発見することにつながる可能性があります。\n\n4.1.4.1 散布図\n\n# seabornを使った散布図の作成\nsns.scatterplot(\n    data=penguins,\n    x=\"bill_length_mm\",\n    y=\"bill_depth_mm\",\n    # 塗り分けの変数の指定\n    hue=\"species\",\n)\nplt.show()\n\n\n\n\n複数の変数の組み合わせについて散布図を作成するには、seabornのpairplot()関数を利用します。\n\nsns.pairplot(penguins, hue=\"species\")\nplt.show()\n\n\n\n\npairplot()関数はデータフレームの数値データの組み合わせについて散布図を作成します。body_mass_gとbody_mass_gのように、自分自身との組み合わせについてはヒストグラムを描画します。pairplot()の出力のような変数の組み合わせに対応する散布図とヒストグラムなどをひとまとめにしたものを散布図行列と呼びます。\n\n\n4.1.4.2 箱ひげ図\nペンギンデータの数値変数の分布を箱ひげ図を用いて確認します。箱ひげ図はseabornのboxplot()関数を使って作成します。\n\nfig, axes = plt.subplots(1, 2, figsize=(12, 5))\nsns.boxplot(x=\"species\", y=\"bill_length_mm\", data=penguins, ax=axes[0])\nsns.boxplot(x=\"species\", y=\"bill_depth_mm\", data=penguins, ax=axes[1])\nplt.show()\n\n\n\n\n\n\n\n\n\n\nノート\n\n\n\n\n同様にflipper_length_mmとbody_mass_gについても箱ひげ図を作成しましょう。\nここで示した散布図、箱ひげ図のほかのデータ可視化方法を調べて実行してみましょう。"
  },
  {
    "objectID": "week04/0401_penguins.html#footnotes",
    "href": "week04/0401_penguins.html#footnotes",
    "title": "4  南極大陸に生育するペンギンの体長データ",
    "section": "",
    "text": "文字列データは数値データとは異なるため、算術平均を計算することはできません。そのため、平均値や標準偏差などの統計量の出力はNaN(Not a Number)として表示されます。一方で数値データは文字列データとは異なり、最頻値を計算することはできません。そのため、最頻値の出力はNaNとして表示されます。↩︎"
  },
  {
    "objectID": "week04/0402_classification.html#scikit-learnを使った機械学習モデルの構築",
    "href": "week04/0402_classification.html#scikit-learnを使った機械学習モデルの構築",
    "title": "5  ペンギンデータの分類に挑戦",
    "section": "5.1 scikit-learnを使った機械学習モデルの構築",
    "text": "5.1 scikit-learnを使った機械学習モデルの構築\nペンギンデータをロジスティック回帰モデルによって分類します。\n\n5.1.1 前処理\n具体的には欠損値への対応とラベルエンコーディングを実行します。\nロジスティック回帰など、いくつかの機械学習モデルは欠損値を含むデータを直接扱うことができません。そのため、欠損値を含む行を削除するか、欠損値を別の値に置き換える必要があります。今回はpandasのdropna()関数で欠損値を含む行を削除します。\n\n# 1/2 欠損値を含む行を削除\npenguins.dropna(inplace=True)  # 元のデータフレームを書き換える場合、inplace=Trueを指定する\n\n# 11行削除されていることを確認\npenguins.shape\n\n(333, 7)\n\n\n続いてラベルエンコーディングを適用します。ラベルエンコーディングとは、カテゴリ変数を数値に変換する処理です。例えば、species列の値Adelie、Chinstrap、Gentooをそれぞれ0, 1, 2に変換します。機械学習モデルは数値データを扱うため、カテゴリ変数を数値に変換する必要があります。ペンギンデータの場合、speciesの他にislandやsex列もカテゴリ変数なのでラベルエンコーディングを適用対象となります。ラベルエンコーディングはscikit-learnのLabelEncoderクラスを使って実行します。\n\n# 2/2 ラベルエンコーディング\n# LabelEncoderクラスのインスタンスを作成\nle = LabelEncoder()\n# 以下のコードの実行で、species列の値Adelie、Chinstrap、Gentooがそれぞれ0, 1, 2に変換される\npenguins[\"species\"] = le.fit_transform(penguins[\"species\"])\n# island列とsex列についても同様にラベルエンコーディングを実行\npenguins[\"island\"] = le.fit_transform(penguins[\"island\"])\npenguins[\"sex\"] = le.fit_transform(penguins[\"sex\"])\n\n\n# 前処理を行ったデータを表示\n# ラベルエンコーディングが適用された3列に注目\npenguins\n\n\n\n\n\n\n\n\nspecies\nisland\nbill_length_mm\nbill_depth_mm\nflipper_length_mm\nbody_mass_g\nsex\n\n\n\n\n0\n0\n2\n39.1\n18.7\n181.0\n3750.0\n1\n\n\n1\n0\n2\n39.5\n17.4\n186.0\n3800.0\n0\n\n\n2\n0\n2\n40.3\n18.0\n195.0\n3250.0\n0\n\n\n4\n0\n2\n36.7\n19.3\n193.0\n3450.0\n0\n\n\n5\n0\n2\n39.3\n20.6\n190.0\n3650.0\n1\n\n\n...\n...\n...\n...\n...\n...\n...\n...\n\n\n338\n2\n0\n47.2\n13.7\n214.0\n4925.0\n0\n\n\n340\n2\n0\n46.8\n14.3\n215.0\n4850.0\n0\n\n\n341\n2\n0\n50.4\n15.7\n222.0\n5750.0\n1\n\n\n342\n2\n0\n45.2\n14.8\n212.0\n5200.0\n0\n\n\n343\n2\n0\n49.9\n16.1\n213.0\n5400.0\n1\n\n\n\n\n333 rows × 7 columns\n\n\n\n\n\n\n元の値\nラベルエンコーディング後の値\n\n\n\n\nAdelie\n0\n\n\nChinstrap\n1\n\n\nGentoo\n2\n\n\n\n\n\n5.1.2 データ分割\n\n訓練データ: モデルの学習に用いるデータ。モデルはこのデータの特徴を学習し、テストデータに対する予測を行うためのパラメータを決定する。\nテストデータ: モデルの予測精度を評価するためのデータ。モデルの学習には用いられない。\n\n\n# 目的変数をspecies列、説明変数をspecies列以外の列とする\n# X... 説明変数のみからなるデータフレーム\n# y... 目的変数のみからなるデータフレーム\nX = penguins.drop(columns=\"species\")\ny = penguins[\"species\"]\n\n# 訓練データとテストデータに分割\n# test_sizeでテストデータの割合を指定する。ここでは全体の20%をテストデータとする（80%を訓練データとする）\n# random_stateは乱数のシードを指定する引数。この値を変更すると結果が変わるので注意\nX_train, X_test, y_train, y_test = train_test_split(\n    X, y, test_size=0.2, random_state=20230508\n)\n\n\n\n5.1.3 モデルの構築\nsklearn.linear_modelモジュールのLogisticRegressionを使ってロジスティック回帰モデルを構築します。\n\n# ロジスティック回帰モデルを適用し、モデルを訓練\n# max_iter引数でパラメータ探索のための試行回数を設定（デフォルトでは100）\nlr = LogisticRegression(max_iter=1000)\n# 訓練データを使ってモデルを訓練\nlr.fit(X_train, y_train)\n\nLogisticRegression(max_iter=1000)In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.LogisticRegressionLogisticRegression(max_iter=1000)\n\n\n\n\n5.1.4 モデルの予測\n構築したモデルに対して、テストデータを使って予測を行います。lr.predict(X_test)を実行すると、テストデータに対する予測結果が得られます。\n\n# テストデータを使って予測を行う\ny_pred = lr.predict(X_test)\n\n# 予測結果は配列で格納されている\ny_pred\n\narray([1, 1, 0, 2, 2, 1, 2, 2, 0, 1, 2, 2, 0, 1, 2, 2, 0, 1, 1, 0, 0, 0,\n       1, 1, 2, 0, 2, 2, 0, 2, 0, 1, 2, 0, 2, 0, 0, 0, 0, 0, 2, 0, 0, 0,\n       1, 1, 0, 0, 2, 0, 2, 0, 0, 2, 2, 2, 2, 0, 1, 1, 1, 0, 0, 2, 0, 2,\n       2])\n\n\nロジスティック回帰モデルでは、各クラス（ここではペンギンの種名）に属する確率を出力することもできます。構築したモデルのインスタンスとpredict_proba()関数を実行すると、各データポイントに対するクラスの所属確率を配列として取得できます。\n\n# テストデータがどのクラスに属するかの確率を出力\nprobabilities = lr.predict_proba(X_test)\n\nペンギンの種名は3つのクラスに分類されるので、predict_proba()関数の出力は3列の配列となります。各データポイントに対して、それぞれのクラスに属する確率が出力されています。このうち、最も確率が高いクラスが予測結果となります。\n\n# テストデータの一件目のデータポイントに対するクラス別の所属確率\n# 表示を見やすくするために、小数点以下4桁まで表示するように設定\nnp.set_printoptions(suppress=True, formatter={\"float\": \"{:.4f}\".format})\nprint(probabilities[0])\n\n[0.0010 0.9986 0.0004]\n\n\n\n# 実際の予測結果\ny_pred[0]\n\n1"
  },
  {
    "objectID": "week04/0402_classification.html#モデルの評価",
    "href": "week04/0402_classification.html#モデルの評価",
    "title": "5  ペンギンデータの分類に挑戦",
    "section": "5.2 モデルの評価",
    "text": "5.2 モデルの評価\n\n# 真の値であるy_testと予測値のy_predを比較して2つの値がどの程度一致しているかを確認する\n# y_testをデータフレームに変換\ny_test_df = pd.DataFrame(y_test)\n# y_predをデータフレームに変換\ny_pred_df = pd.DataFrame(y_pred, columns=[\"predicted\"], index=y_test.index)\n\n# y_testとy_predのデータフレームを結合\ncomparison_df = pd.concat([y_test_df, y_pred_df], axis=1)\n\n# speciesとpredictedが一致しているかどうかを確認\ncomparison_df[\"correct\"] = comparison_df[\"species\"] == comparison_df[\"predicted\"]\n\n# TrueとFalseの数をカウント\ncomparison_df.groupby(\"correct\").size().reset_index(name=\"count\")\n\n\n\n\n\n\n\n\ncorrect\ncount\n\n\n\n\n0\nFalse\n1\n\n\n1\nTrue\n66\n\n\n\n\n\n\n\n\n\n一致した件数は 66/67件です。これは、モデルが正しく予測できたデータの割合が約98%であることを意味します。\n\n\nscikit-learnには、モデルの評価を行うための様々な関数が用意されています。ここでは、sklearn.metricsモジュールの関数を使ってモデルの評価を行います。\naccuracy_score()関数は、正解率を計算する関数です。正解率は、正しく予測できたデータの割合を表します。この値は先ほど確認した正解率と一致します。\n\n# モデルを評価\nprint(\"Accuracy:\", accuracy_score(y_test, y_pred))\n\nAccuracy: 0.9850746268656716\n\n\n種名ごとの精度を確認するためにclassification_report()関数を使います。\n\nprint(\"Classification Report:\\n\", classification_report(y_test, y_pred))\n\nClassification Report:\n               precision    recall  f1-score   support\n\n           0       1.00      0.97      0.98        29\n           1       0.93      1.00      0.97        14\n           2       1.00      1.00      1.00        24\n\n    accuracy                           0.99        67\n   macro avg       0.98      0.99      0.98        67\nweighted avg       0.99      0.99      0.99        67\n\n\n\n各クラスごとに、 precision、recall、f1-score、supportの4つの値が表示されます。それぞれの値の意味は以下の通りです。\n\nprecision: 適合率。正と予測したデータのうち、実際に正であるものの割合。\nrecall: 再現率。実際に正であるもののうち、正であると予測されたものの割合。\nf1-score: 適合率と再現率の調和平均により得られた値。適合率と再現率のバランスを考慮した評価指標。この値が高いほど、適合率と再現率の両方が高いことを示す。\nsupport: 分類されたデータ数。\n\nここで出力される評価指標についてはaccuracy_score()関数のように個別の関数を使った算出も可能です。具体的にはprecisionはprecision_score()、recallはrecall_score()、f1-scoreはf1_score()関数を利用します。\n\n5.2.1 混合行列\n最後に、分類モデルの性能評価に使われる混合行列を確認しましょう。混合行列は、モデルの予測結果と実際のクラスの関係を4つの要素に分類した行列です。以下の4つの要素に分類されます。\n\nTrue Positive（TP）：正のクラスを正と予測し、実際に正である場合。\nFalse Positive（FP）：正のクラスを正と予測したが、実際には負である場合。\nTrue Negative（TN）：負のクラスを負と予測し、実際に負である場合。\nFalse Negative（FN）：負のクラスを負と予測したが、実際には正である場合。\n\nscikit-learnでは、confusion_matrix()関数を使って混合行列を作成できます。ここではさらに、ConfusionMatrixDisplay()関数を使って混合行列を可視化する例を示します。\n\ncm = confusion_matrix(y_test, y_pred)\n\ndisp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=lr.classes_)\n\ndisp.plot()\nplt.show()\n\n\n\n\n混合行列を見ることで、どのクラスが誤分類されやすいかを確認することができます。また、適合率や再現率の値がどのように計算されているかを理解することができます。\n具体的には以下のように計算されます。\n\n適合率: TP / (TP + FP)\n再現率: TP / (TP + FN)\n\n\n\n\n\n\n\nノート\n\n\n\n\n数値変数の標準化、ラベルエンコーディングの代わりにダミー変数化を行ったデータでモデルの学習を行いましょう。"
  },
  {
    "objectID": "references.html",
    "href": "references.html",
    "title": "参考資料・URL",
    "section": "",
    "text": "AI白書編集委員会. 2022. Ai白書2022. KADOKAWA.\n\n\nAlice Zheng, Amanda Casari, and ホクソエム. 2019.\n機械学習のための特徴量エンジニアリング :\nその原理とPythonによる実践. Translated by ホクソエム.\nオライリー・ジャパン. http://id.ndl.go.jp/bib/029512290.\n\n\nGéron, Aurélien, 下田倫大, and 長尾高弘. 2020.\nScikit-Learn、keras、TensorFlowによる実践機械学習. Translated\nby 下田倫大 and 長尾高弘. 第2版 ed. オライリー・ジャパン. http://id.ndl.go.jp/bib/030701507.\n\n\nGrus, Joel, and 菊池彰. 2020. ゼロからはじめるデータサイエンス :\nPythonで学ぶ基本と実践. Translated by 菊池彰. 第2版 ed.\nオライリー・ジャパン. http://id.ndl.go.jp/bib/030372878.\n\n\nSweigart, Al, and 相川愛三. 2023. 退屈なことはPythonにやらせよう :\nノンプログラマーにもできる自動化処理プログラミング. Translated by\n相川愛三. 第2版 ed. オライリー・ジャパン.\n\n\n八谷大岳. 2020. ゼロからつくるPython機械学習プログラミング入門 =\nIntroduction to Machine Learning from Scratch with Python.\n機械学習スタートアップシリーズ. 講談社. http://id.ndl.go.jp/bib/030584765.\n\n\n吉田拓真, and 尾原颯. 2018. 現場で使える!NumPyデータ処理入門 :\n機械学習・データサイエンスで役立つ高速処理手法. 翔泳社. http://id.ndl.go.jp/bib/029316312.\n\n\n小林一郎. 2008. 人工知能の基礎. Computer Science Library ; 13.\nサイエンス社. http://id.ndl.go.jp/bib/000009788211.\n\n\n岡谷貴之. 2022. 深層学習 = Deep Learning. 改訂第2版 ed.\n機械学習プロフェッショナルシリーズ. 講談社. http://id.ndl.go.jp/bib/031901202.\n\n\n岡野原大輔. 2022a. ディープラーニングを支える技術. Tech×books\nPlus 2. 技術評論社. http://id.ndl.go.jp/bib/032086743.\n\n\n———. 2022b. ディープラーニングを支える技術 :\n「正解」を導くメカニズム〈技術基礎〉. Tech×books Plus. 技術評論社.\nhttp://id.ndl.go.jp/bib/031881422.\n\n\n有賀友紀, and 大橋俊介. 2021.\nRとPythonで学ぶ実践的データサイエンス&機械学習. 増補改訂版.\n技術評論社. http://id.ndl.go.jp/bib/031401828.\n\n\n椎名洋, 姫野哲人, 保科架風, and 清水昌平. 2019.\nデータサイエンスのための数学 = Mathematics for Data Science.\nEdited by 清水昌平. データサイエンス入門シリーズ. 講談社. http://id.ndl.go.jp/bib/029903862.\n\n\n池内孝啓, and 片柳薫子. 2020.\nPythonユーザのためのJupyter〈実践〉入門. 改訂版. 技術評論社. http://id.ndl.go.jp/bib/030570561.\n\n\n石川聡彦. 2018. 人工知能プログラミングのための数学がわかる本 =\nMATHEMATICS FOR AI PROGRAMMING. KADOKAWA. http://id.ndl.go.jp/bib/028819866.\n\n\n谷口忠大. 2020. イラストで学ぶ人工知能概論 = an Illustrated Guide to\nArtificial Intelligence. 改訂第2版 ed. 講談社. http://id.ndl.go.jp/bib/030810109.\n\n\n赤穂昭太郎, 今泉允聡, 内田誠一, 清智也, 高野渉, 辻真吾, 原尚幸, et al.\n2023. 応用基礎としてのデータサイエンス : AI×データ活用の実践.\nEdited by 北川源四郎 and 竹村彰通. データサイエンス入門シリーズ. 講談社.\nhttp://id.ndl.go.jp/bib/032637501.\n\n\n門脇大輔, 阪田隆司, 保坂桂佑, and 平松雄司. 2019.\nKaggleで勝つデータ分析の技術. 技術評論社. http://id.ndl.go.jp/bib/029976550."
  }
]