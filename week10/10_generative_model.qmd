---
title: 深層生成モデル
execute:
  keep-ipynb: true
jupyter:
  jupytext:
    formats: 'ipynb,qmd'
    text_representation:
      extension: .qmd
      format_name: quarto
      format_version: '1.0'
      jupytext_version: 1.14.5
  kernelspec:
    display_name: Python 3 (ipykernel)
    language: python
    name: python3
---

:::{.callout-caution}

このページの内容は大部分が書きかけです。文の流れが整っていなかったりまとまりがないことがあります。

:::

## 識別モデルと生成モデル

機械学習の手法の分類方法として、教師あり学習と教師なし学習を紹介してきました。一方、出力の種類に着目すると、識別モデルと生成モデルに分類することもできます。識別モデルは、ロジスティック回帰やサポートベクターマシンのように機械学習の中でも最もよく使われるモデルの一つです。

識別モデルの多くは、教師あり学習の一種として扱われます。具体的には、訓練データに正解ラベルが付いている学習を行うことで、入力データから正解ラベルを予測することができます。入力データ $x$ が与えられたときに、そのデータがクラス $y$ に属する確率 $p(y|x)$ を求めるモデルが識別モデルです。

$p(y|x)$ のような関係を条件付き確率と呼びます。条件付き確率は、ある事象が起こったときに、別の事象が起こる確率を表すものです。ペンギンの種を表現する特徴量が与えられたときに、そのペンギンが特定のペンギンの種である確率を求めることができます。

一方、生成モデルは、与えられたデータから新しいデータを生成するモデルです。生成モデルは、既存のデータの特徴やパターンを学習し、それを元に新たなデータを生成する能力を持ちます。少し難しい言い方をすれば、生成モデルは入力データを与えたときに、そのデータが*どのような分布から生成されたのかを推定する確率モデル*です。これらは密度推定問題を解くためのモデルです。

入力 $x$ が観測される確率 $p(x)$ を求めることを密度推定と呼びます。生成モデルは、密度推定を行うことで、入力データの分布を学習します。

確率モデルから新たなデータを生成することは、機械学習の分野ではサンプリングと呼ばれます。生成モデルは、サンプリングを行うことで、新たなデータを生成することができます。

生成モデルを用いると、例えば、入力データが犬の画像だった場合、生成モデルはその犬の画像と似たような犬の画像を生成できます。似たような、というのは、生成モデルが完璧に同じ画像を生成することはほぼないためです。生成モデルは、入力データの分布を学習することで、その分布に基づいて新たなデータを生成することができるのです。

生成モデルの学習から新たなデータの生成までの過程は次のようになります。まず、訓練データから、そのデータの分布を表す確率分布を学習します。次にランダムノイズを入力として、学習した確率分布に基づく新たなデータを生成します。生成されたデータは、訓練データと同じ確率分布に従っているため、訓練データと同じようなデータが生成されることになります。

生成モデルはその特性から、画像や文章を使った創作活動に適しています。生成モデルを用いることで、白黒の画像をカラー画像に変換することができます。また、ある作家の文章のスタイルを学習し、そのスタイルに基づいて新たな文章を生成することができます。CNNやRNNを用いた深層生成モデルの進歩は、AIによる芸術作品の創造、自然言語処理などの領域で革新的な成果を生み出しています。

## 敵対的生成ネットワーク

深層生成モデルの代表的な手法の一つは、敵対的生成ネットワーク（Generative Adversarial Networks: GAN）です。GANは、生成器と分類器の2つのネットワークで構成されています。生成器ではランダムノイズなどの入力から新しいデータを生成します。もう一方のネットワークである識別器は、生成されたデータと本物のデータを識別する役割を持ちます。このとき、扱うデータが画像であればCNN、文章であればRNNというように、データの種類に応じたネットワークを用います。この2つのネットワークを競わせながら学習を進めることで、高品質な新しいデータを生成することが可能となります。

GANの学習手順は次のようになります。まず、生成器はランダムノイズなどの入力からサンプルを生成します。生成されたサンプルと本物のサンプルを識別器に入力し、それが本物かどうかを判別します。このとき、生成器は識別器を騙すように学習を進めます。一方、識別器は生成器が生成した画像を本物と判別できるように学習を進めます。学習は、識別器が本物と生成器によるサンプルを区別できなくなるまで繰り返されます。

つまり、生成器と識別器は互いに競争する形で学習を進めます。生成器は本物のデータに近いサンプルを生成し、識別器を欺く能力を高めることを目指します。一方、識別器は生成器が生成した偽物と本物のデータを正しく識別できるように学習を行います。

:::{.callout-tip}
Tensorflow公式によるGANのデモ: https://www.tensorflow.org/tutorials/generative/dcgan?hl=ja
:::

## 表現学習

表現学習

## テンソル

カラー画像は4つの次元を持つテンソルで表現されます。3つの次元は画像の高さ、幅、色のチャンネル数を表します。4つ目の次元は画像の枚数を表します。

## 変分自己符号化器（変分オートエンコーダ）
